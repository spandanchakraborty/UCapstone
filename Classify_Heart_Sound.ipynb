{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As part of preprocessing, the Mels co-effs are extracted from All 21 Labeled Audion file and been pickled in labeled_mel_dict.p.  We have another pickled file which contains the location of the Heart Sound in respective wav files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileloc='/Users/spandan.chakraborty/Documents/UML/Capstone/HS/Mycode/Mels/Code/'\n",
    "filename='labeled_mel_dict.p'\n",
    "#sound_locations='/Users/spandan.chakraborty/Documents/UML/Capstone/HS/Mycode/Mels/labels/set_a_timing_csv.p'\n",
    "sound_locations=fileloc+'set_a_timing_csv.p'\n",
    "### df is a dictionary of All mels co effs (128 mels* duration of the file)\n",
    "df=pd.read_pickle(fileloc+filename)\n",
    "### df_sound_loc contains the location of the Heart Sound\n",
    "df_sound_loc=pd.read_pickle(sound_locations)\n",
    "#print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 684)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  8.04295694e-03,   8.93476285e-02,   4.81661272e-01, ...,\n",
       "          1.65827122e+00,   1.63090038e+00,   2.36399915e+00],\n",
       "       [  1.56986214e-02,   1.74392900e-01,   9.40129107e-01, ...,\n",
       "          3.23669169e+00,   3.18326802e+00,   4.61416465e+00],\n",
       "       [  2.43042414e-01,   3.93015880e-01,   6.82248374e-01, ...,\n",
       "          6.73354401e-01,   1.07922115e+00,   3.23077510e+00],\n",
       "       ..., \n",
       "       [  1.87514210e-06,   5.44098180e-07,   1.67955814e-06, ...,\n",
       "          1.61014473e-07,   2.96333669e-06,   5.41442064e-05],\n",
       "       [  1.90644479e-07,   1.50682207e-06,   2.07056151e-06, ...,\n",
       "          5.78843901e-07,   4.55531865e-06,   6.18284918e-05],\n",
       "       [  4.18645852e-07,   2.09581515e-06,   4.93758600e-06, ...,\n",
       "          2.27469929e-06,   2.57632735e-06,   3.87966964e-05]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Example of a dictionary \n",
    "print(df['normal__201108011118'].shape)\n",
    "### audio info converted into Array (mels_Co_eff)\n",
    "# each file represents 128 Mel Co effs .. since each file contains variable length of Audio the segment Size varies\n",
    "df['normal__201108011118']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>cycle</th>\n",
       "      <th>sound</th>\n",
       "      <th>location</th>\n",
       "      <th>TimeInSec</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>set_a/normal__201108011118.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>7591</td>\n",
       "      <td>0.172132</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>set_a/normal__201108011118.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>20496</td>\n",
       "      <td>0.464762</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fname  cycle sound  location  TimeInSec  segment\n",
       "366  set_a/normal__201108011118.wav      1    S1      7591   0.172132       14\n",
       "367  set_a/normal__201108011118.wav      1    S2     20496   0.464762       40"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Heart Sound Location Labels\n",
    "df_sound_loc[df_sound_loc.fname.str.contains('normal__201108011118')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sound_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sound_loc.fname=df_sound_loc.fname.str.replace('set_a/','')\n",
    "df_sound_loc.fname=df_sound_loc.fname.str.replace('.wav','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>cycle</th>\n",
       "      <th>sound</th>\n",
       "      <th>location</th>\n",
       "      <th>TimeInSec</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>normal__201108011118</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>7591</td>\n",
       "      <td>0.172132</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>normal__201108011118</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>20496</td>\n",
       "      <td>0.464762</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fname  cycle sound  location  TimeInSec  segment\n",
       "366  normal__201108011118      1    S1      7591   0.172132       14\n",
       "367  normal__201108011118      1    S2     20496   0.464762       40"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sound_loc[df_sound_loc.fname.str.contains('normal__201108011118')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### The Window width for Librosa is 512 samples per segment\n",
    "### The input label as Given in Kaggle is as per 44100 frames per seconf sample rate\n",
    "### Converting the labeled location into Segment \n",
    "df_sound_loc['segment']=(df_sound_loc['location']/512).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since HS lasts approx. 0.11- 0.14  secs & 1 sec of wav file contains 87 segments (for 44100 Sample Rate and 512 Hop length (window size  512 samples)).. it turns out the HS will be of 0.14*87  ~= 12 segment long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sound_loc['HS_Start']=(df_sound_loc['segment']-6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sound_loc['HS_End']=(df_sound_loc['segment']+6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>cycle</th>\n",
       "      <th>sound</th>\n",
       "      <th>location</th>\n",
       "      <th>TimeInSec</th>\n",
       "      <th>segment</th>\n",
       "      <th>HS_Start</th>\n",
       "      <th>HS_End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>normal__201108011118</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>7591</td>\n",
       "      <td>0.172132</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>normal__201108011118</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>20496</td>\n",
       "      <td>0.464762</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fname  cycle sound  location  TimeInSec  segment  \\\n",
       "366  normal__201108011118      1    S1      7591   0.172132       14   \n",
       "367  normal__201108011118      1    S2     20496   0.464762       40   \n",
       "\n",
       "     HS_Start  HS_End  \n",
       "366         8      20  \n",
       "367        34      46  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sound_loc[df_sound_loc.fname.str.contains('normal__201108011118')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the Noise Space in the mels , Want to get same 13 Width Mel time window for noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Shift(-1) function returns values from Next Row respective to current row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_sound_loc['noise_window']=df_sound_loc['HS_Start'].shift(-1)-df_sound_loc['HS_End']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the noise window between Heart Sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sound_loc['n_start']=df_sound_loc.groupby('fname')['HS_End'].apply(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shift(-1) provides the next row reference\n",
    "df_sound_loc['n_end']=df_sound_loc.groupby('fname')['HS_Start'].shift(-1).apply(lambda x:x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_sound_loc[df_sound_loc.fname.str.contains('normal__201108011118')]\n",
    "# df_sound_loc[df_sound_loc.fname.str.contains('normal__201108011114')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n"
     ]
    }
   ],
   "source": [
    "df_noise=pd.DataFrame()\n",
    "df_noise=df_sound_loc.copy()\n",
    "print(len(df_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   2,   4,   6,   8,  10,  12,  14,  16,  18,\n",
       "            ...\n",
       "            280, 282, 288, 292, 370, 372, 376, 380, 384, 388],\n",
       "           dtype='int64', length=111)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude the lines where n_start-n_end <12 segments\n",
    "df_noise[(df_noise['n_end']-df_noise['n_start'])<12].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### This is an Important Temporal Information I am going to drop, \n",
    "### with this the relative Timiing Gaps pattern between HS1 - HS2 -HS1 will be lost \n",
    "### But since I am only ineterested in Fifferentiating from HS 1 to HS2 to Noise .. \n",
    "### I will drop this info for time being\n",
    "#df_noise.iloc[df_noise[(df_noise['n_end']-df_noise['n_start'])<12].index].apply(lambda x: x['n_end']-x['n_start'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noise.drop(df_noise[(df_noise['n_end']-df_noise['n_start'])<12].index, inplace=True)\n",
    "len(df_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noise.dropna(how='any', inplace=True)  ## Any row Has nan value will be dropped\n",
    "len(df_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_noise.n_end.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_noise.n_end=df_noise.n_end.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>cycle</th>\n",
       "      <th>sound</th>\n",
       "      <th>location</th>\n",
       "      <th>TimeInSec</th>\n",
       "      <th>segment</th>\n",
       "      <th>HS_Start</th>\n",
       "      <th>HS_End</th>\n",
       "      <th>n_start</th>\n",
       "      <th>n_end</th>\n",
       "      <th>nn_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>20759</td>\n",
       "      <td>0.470726</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "      <td>47244</td>\n",
       "      <td>1.071293</td>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>116</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fname  cycle sound  location  TimeInSec  segment  HS_Start  \\\n",
       "1  normal__201102081321      1     n     20759   0.470726       40        34   \n",
       "3  normal__201102081321      2     n     47244   1.071293       92        86   \n",
       "\n",
       "   HS_End  n_start  n_end  nn_end  \n",
       "1      46       47     61      59  \n",
       "3      98       99    116     111  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noise['nn_end']=df_noise.n_start+12\n",
    "df_noise.sound='n'\n",
    "df_noise.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>sound</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>S1</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>S2</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fname sound  start  end\n",
       "0  normal__201102081321    S1     13   25\n",
       "1  normal__201102081321    S2     34   46"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hs=pd.DataFrame()\n",
    "df_hs=df_sound_loc.copy()\n",
    "df_hs.drop(['cycle','location','TimeInSec','segment','n_start','n_end'], axis=1, inplace=True)\n",
    "df_hs.rename(columns={'HS_Start': 'start','HS_End':'end'}, inplace=True)\n",
    "df_hs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>sound</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>n</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>n</td>\n",
       "      <td>99</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fname sound  start  end\n",
       "1  normal__201102081321     n     47   59\n",
       "3  normal__201102081321     n     99  111"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noise.drop(['cycle','location','TimeInSec','segment','HS_Start','HS_End','n_end'], axis=1, inplace=True)\n",
    "df_noise.rename(columns={'n_start':'start','nn_end':'end'}, inplace=True)\n",
    "df_noise.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sound\n",
       "S1    195\n",
       "S2    195\n",
       "n     258\n",
       "dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s=pd.concat([df_hs,df_noise], axis=0)\n",
    "print(len(df_s))\n",
    "df_s.groupby('sound').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get the Mels value from Dictionary using File names as key through map \n",
    "#### The idea is to Slice the 128 mels of 0.14 secs of Slices (Almost 12 segements around the HS labled Locations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_s['mels']=df_sound_loc['fname'].map(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>sound</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>mels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>normal__201108011118</td>\n",
       "      <td>S1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>[[0.00804295694391, 0.089347628485, 0.48166127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>normal__201108011118</td>\n",
       "      <td>S2</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>[[0.00804295694391, 0.089347628485, 0.48166127...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fname sound  start  end  \\\n",
       "366  normal__201108011118    S1      8   20   \n",
       "367  normal__201108011118    S2     34   46   \n",
       "\n",
       "                                                  mels  \n",
       "366  [[0.00804295694391, 0.089347628485, 0.48166127...  \n",
       "367  [[0.00804295694391, 0.089347628485, 0.48166127...  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s[df_s.fname.str.contains('normal__201108011118')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Following code used list Slicing fetching the Heart Sound location specific Mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_s['mels_seg'] = df_s.apply(lambda x: x['mels'][:, x['start']:x['end']].tolist(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>sound</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>mels</th>\n",
       "      <th>mels_seg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>S1</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>[[0.0752865622903, 0.00439239454838, 0.0182232...</td>\n",
       "      <td>[[0.0171469795289, 0.0173154008662, 0.39569554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>S2</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>[[0.0752865622903, 0.00439239454838, 0.0182232...</td>\n",
       "      <td>[[0.0471267533454, 0.0061760868171, 0.00564760...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fname sound  start  end  \\\n",
       "0  normal__201102081321    S1     13   25   \n",
       "1  normal__201102081321    S2     34   46   \n",
       "\n",
       "                                                mels  \\\n",
       "0  [[0.0752865622903, 0.00439239454838, 0.0182232...   \n",
       "1  [[0.0752865622903, 0.00439239454838, 0.0182232...   \n",
       "\n",
       "                                            mels_seg  \n",
       "0  [[0.0171469795289, 0.0173154008662, 0.39569554...  \n",
       "1  [[0.0471267533454, 0.0061760868171, 0.00564760...  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_sound_loc[df_sound_loc.fname.str.contains('normal__201106111136')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 12)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df_s.ix[0, 'mels_seg']).shape  ## np.array converts the list to Array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>sound</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>mels</th>\n",
       "      <th>mels_seg</th>\n",
       "      <th>class</th>\n",
       "      <th>mels_flatten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>S1</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>[[0.0752865622903, 0.00439239454838, 0.0182232...</td>\n",
       "      <td>[[0.0171469795289, 0.0173154008662, 0.39569554...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0171469795289, 0.0173154008662, 0.395695541...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal__201102081321</td>\n",
       "      <td>S2</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>[[0.0752865622903, 0.00439239454838, 0.0182232...</td>\n",
       "      <td>[[0.0471267533454, 0.0061760868171, 0.00564760...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0471267533454, 0.0061760868171, 0.005647608...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fname sound  start  end  \\\n",
       "0  normal__201102081321    S1     13   25   \n",
       "1  normal__201102081321    S2     34   46   \n",
       "\n",
       "                                                mels  \\\n",
       "0  [[0.0752865622903, 0.00439239454838, 0.0182232...   \n",
       "1  [[0.0752865622903, 0.00439239454838, 0.0182232...   \n",
       "\n",
       "                                            mels_seg            class  \\\n",
       "0  [[0.0171469795289, 0.0173154008662, 0.39569554...  [1.0, 0.0, 0.0]   \n",
       "1  [[0.0471267533454, 0.0061760868171, 0.00564760...  [0.0, 1.0, 0.0]   \n",
       "\n",
       "                                        mels_flatten  \n",
       "0  [0.0171469795289, 0.0173154008662, 0.395695541...  \n",
       "1  [0.0471267533454, 0.0061760868171, 0.005647608...  "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.drop('mels', inplace=True)\n",
    "#df_s.head(2)\n",
    "S1=np.array([1.0,0.0,0.0])\n",
    "S2=np.array([0.0,1.0,0.0])\n",
    "n=np.array([0.0,0.0,1.0])\n",
    "sound_class={'S1':S1,'S2':S2,'n':n}\n",
    "df_s['class']=df_s['sound'].map(sound_class)\n",
    "#df_s['mels_flatten']=df_s['mels_seg'].apply(lambda x: np.asarray(x).flatten())\n",
    "df_s['mels_flatten']=df_s['mels_seg'].apply(np.ravel)\n",
    "df_s.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if all the elements in the Dataset is correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1536,    0])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s['mels_flatten'].apply(len).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It indicates there are 0 length Data elements in mels_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([136, 294], dtype='int64')"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s[df_s['mels_flatten'].apply(len)==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>sound</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>mels</th>\n",
       "      <th>mels_seg</th>\n",
       "      <th>class</th>\n",
       "      <th>mels_flatten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>normal__201105011626</td>\n",
       "      <td>S1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>[[0.147678276527, 0.040960011283, 0.0059928980...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>normal__201106221450</td>\n",
       "      <td>S1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>[[0.000655332564528, 0.0046009260886, 0.067146...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fname sound  start  end  \\\n",
       "136  normal__201105011626    S1     -1   11   \n",
       "294  normal__201106221450    S1     -1   11   \n",
       "\n",
       "                                                  mels  \\\n",
       "136  [[0.147678276527, 0.040960011283, 0.0059928980...   \n",
       "294  [[0.000655332564528, 0.0046009260886, 0.067146...   \n",
       "\n",
       "                                              mels_seg            class  \\\n",
       "136  [[], [], [], [], [], [], [], [], [], [], [], [...  [1.0, 0.0, 0.0]   \n",
       "294  [[], [], [], [], [], [], [], [], [], [], [], [...  [1.0, 0.0, 0.0]   \n",
       "\n",
       "    mels_flatten  \n",
       "136           []  \n",
       "294           []  "
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.iloc[[136,294]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## drop the rogue elements \n",
    "df_s.drop(df_s.index[[136,294]], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1536])"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s['mels_flatten'].apply(len).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sound\n",
       "S1    193\n",
       "S2    195\n",
       "n     257\n",
       "dtype: int64"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.groupby('sound').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sound_num\n",
       "1    193\n",
       "2    195\n",
       "3    257\n",
       "dtype: int64"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num={'S1':1,'S2':2,'n':3}\n",
    "df_s['sound_num']=df_s['sound'].map(df_num)\n",
    "df_s.groupby('sound_num').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate if we always predict Majority (which is noise): 0.601550387597\n"
     ]
    }
   ],
   "source": [
    "### Establish Baseline for a MultiClass Classification : Zero Rule Classification\n",
    "## Go by Simple Targer Data Distribution:\n",
    "#print(len(df_s))\n",
    "print 'Error Rate if we always predict Majority (which is noise):',(193+195)/(193.+195+257)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645 645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_All=df_s.ix[:,['mels_flatten']]\n",
    "y_All=df_s.ix[:,['class']] \n",
    "# instead of the one hot encoded lets take the label for sound to match the input of tf mnist example\n",
    "#y=df_s.ix[:,['sound_num']] \n",
    "print(X_All.size, y_All.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mels_flatten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0171469795289, 0.0173154008662, 0.395695541...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0471267533454, 0.0061760868171, 0.005647608...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mels_flatten\n",
       "0  [0.0171469795289, 0.0173154008662, 0.395695541...\n",
       "1  [0.0471267533454, 0.0061760868171, 0.005647608..."
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_All.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_All['class'].apply(len).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(645, 1536)\n",
      "(645, 3)\n"
     ]
    }
   ],
   "source": [
    "#X_inp=np.vstack(X['mels_flatten'].values).reshape(X['mels_flatten'].shape[0], 128, 12,1).astype(np.float32)\n",
    "X_inp_flat=np.vstack(X_All['mels_flatten'].values) ## This one is used to pass a flat array to tf\n",
    "X_inp_flat=X_inp_flat.astype(np.float32, copy=False)\n",
    "y_inp=np.vstack(y_All['class'].values)\n",
    "#print(X_inp.shape)\n",
    "print(X_inp_flat.shape)\n",
    "print(y_inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536,)\n",
      "[ 0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "print (X_inp_flat[1].shape)\n",
    "print (y_inp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_s, X_test, y_train_s, y_test = train_test_split(X_inp_flat, y_inp, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(548, 3) (97, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_s.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(438, 3) (78, 3)\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_val_df, y_train, y_val_df = train_test_split(X_train_s, y_train_s, test_size=0.15, random_state=42)\n",
    "# print(y_train.shape, y_val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following TF Mnist set up:\n",
    "https://www.tensorflow.org/get_started/mnist/pros#about_this_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load MNIST Data just for comparision of my array input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start TensorFlow InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders: We start building the computation graph by creating nodes for the input images and target output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 1536], name='x_variable')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 3],name='y_variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here x and y_ aren't specific values. Rather, they are each a placeholder -- a value that we'll input when we ask TensorFlow to run a computation.\n",
    "\n",
    "The input images x will consist of a 2d tensor of floating point numbers. Here we assign it a shape of [None, 1536], where 1536 is the dimensionality of a single flattened 128 mels by 12 segments Audio attributes, and None indicates that the first dimension, corresponding to the batch size, can be of any size. The target output classes y_ will also consist of a 2d tensor, where each row is a one-hot 3-dimensional vector indicating which digit class (1 to 3 corresponding to S1, S2 and Noise) the corresponding Heart Sound the audio section belongs to.\n",
    "\n",
    "The shape argument to placeholder is optional, but it allows TensorFlow to automatically catch bugs stemming from inconsistent tensor shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "\n",
    "We now define the weights W and biases b for our model. We could imagine treating these like additional inputs, but TensorFlow has an even better way to handle them: Variable. A Variable is a value that lives in TensorFlow's computation graph. It can be used and even modified by the computation. In machine learning applications, one generally has the model parameters be Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All variables are initialized with zeros \n",
    "W = tf.Variable(tf.zeros([1536,3]),name='weights')\n",
    "b = tf.Variable(tf.zeros([3]),name='biases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Variables can be used within a session, they must be initialized using that session. This step takes the initial values (in this case tensors full of zeros) that have already been specified, and assigns them to each Variable. This can be done for all Variables at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted Class and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.matmul(x,W) + b\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y), name='cross_entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "Now that we have defined our model and training loss function, it is straightforward to train using TensorFlow. Because TensorFlow knows the entire computation graph, it can use automatic differentiation to find the gradients of the loss with respect to each of the variables. TensorFlow has a variety of built-in optimization algorithms. For this example, we will use steepest gradient descent, with a step length of 0.5, to descend the cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy, name='train_step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our train Size is very small we can train the model in one run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_step.run(feed_dict={x: X_train, y_: y_train})\n",
    "#train_step.run(feed_dict={x: X_train_s, y_: y_train_s})\n",
    "sess.run(train_step, feed_dict={x: X_train_s, y_: y_train_s})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "tf.argmax is an extremely useful function which gives you the index of the highest entry in a tensor along some axis. For example, tf.argmax(y,1) is the label our model thinks is most likely for each input, while tf.argmax(y_,1) is the true label. We can use tf.equal to check if our prediction matches the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1),name='prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.376712\n"
     ]
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='Calc_Accuracy')\n",
    "print(accuracy.eval(feed_dict={x: X_train, y_: y_train}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy on Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.360825\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: X_test, y_: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert sess is tf.get_default_session()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x116f53f90>"
      ]
     },
     "execution_count": 974,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Multilayer Convolutional Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Initialization\n",
    "\n",
    "To create this model, we're going to need to create a lot of weights and biases. One should generally initialize weights with a small amount of noise for symmetry breaking, and to prevent 0 gradients. Since we're using ReLU neurons, it is also good practice to initialize them with a slightly positive initial bias to avoid \"dead neurons\". Instead of doing this repeatedly while we build the model, let's create two handy functions to do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution and Pooling\n",
    "TensorFlow also gives us a lot of flexibility in convolution and pooling operations. How do we handle the boundaries? What is our stride size? In this example, we're always going to choose the vanilla version. Our convolutions uses a stride of one and are zero padded so that the output is the same size as the input. Our pooling is plain old max pooling over 2x2 blocks. To keep our code cleaner, let's also abstract those operations into functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Convolutional Layer\n",
    "\n",
    "We can now implement our first layer. It will consist of convolution, followed by max pooling. The convolution will compute 32 features for each 5x5 patch. Its weight tensor will have a shape of [5, 5, 1, 32]. The first two dimensions are the patch size, the next is the number of input channels, and the last is the number of output channels. We will also have a bias vector with a component for each output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "W_conv1 = weight_variable([2, 6, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the layer, we first reshape x to a 4d tensor, with the second and third dimensions corresponding to Audio Mels Co efficients and Duration converted into Segements (87 segments corresponds to 1 sec of audio in .wav format), and the final dimension for image processing corresponds to the number of color channels, but in my case I just kept it as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_audio = tf.reshape(x, [-1, 128, 12, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool. The max_pool_2x2 method will reduce the image size to 64x6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_audio, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Convolutional Layer\n",
    "\n",
    "In order to build a deep network, we stack several layers of this type. The second layer will have 64 features for each 5x5 patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "#W_conv2 = weight_variable([32, 8, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Densely Connected Layer\n",
    "\n",
    "Now that the image size has been reduced to 7x7, we add a fully-connected layer with 1024 neurons to allow processing on the entire image. We reshape the tensor from the pooling layer into a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([32 * 3 * 64, 1024])\n",
    "#W_fc1 = weight_variable([32 * 3 * 64, 2048])\n",
    "b_fc1 = bias_variable([1024])\n",
    "#b_fc1 = bias_variable([2048])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 32*3*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout\n",
    "\n",
    "To reduce overfitting, we will apply dropout before the readout layer. We create a placeholder for the probability that a neuron's output is kept during dropout. This allows us to turn dropout on during training, and turn it off during testing. TensorFlow's tf.nn.dropout op automatically handles scaling neuron outputs in addition to masking them, so dropout just works without any additional scaling.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readout Layer\n",
    "\n",
    "Finally, we add a layer, just like for the one layer softmax regression above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 3])\n",
    "#W_fc2 = weight_variable([2048, 3])\n",
    "b_fc2 = bias_variable([3])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv), name ='Conv_Cross_Entropy')\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1),name ='Conv_Accuracy')\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2000/2000 [54:04<00:00,  1.68s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.985401\n",
      "Test accuracy 0.762887\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess1:\n",
    "    assert sess1 is tf.get_default_session()\n",
    "    sess1.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in tqdm(range(2000)):\n",
    "        sess1.run(train_step,feed_dict={x: X_train_s, y_: y_train_s, keep_prob: 1.})\n",
    "    \n",
    "    train_accuracy = accuracy.eval(feed_dict={x: X_train_s, y_: y_train_s, keep_prob: 1.})\n",
    "    print('training accuracy', train_accuracy)\n",
    "    \n",
    "#     validiation_accuracy = accuracy.eval(feed_dict={x: X_val_df, y_: y_val_df,keep_prob: 1.})\n",
    "#     print('validation accuracy', validiation_accuracy)\n",
    "    \n",
    "    test_accuracy = accuracy.eval(feed_dict={x: X_test, y_: y_test,keep_prob: 1.})\n",
    "    print('Test accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Higher no# of Epochs and with Keep Proba as 0.5 while training in a different session\n",
    "Keep Proba = 0.5 to ensure we are not overfitting to the Training Data, while Training in Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2500/2500 [1:10:19<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.989051\n",
      "Test accuracy 0.773196\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess2:\n",
    "    assert sess2 is tf.get_default_session()\n",
    "    sess2.run(tf.global_variables_initializer())\n",
    "    for i in tqdm(range(2500)):\n",
    "        sess2.run(train_step,feed_dict={x: X_train_s, y_: y_train_s, keep_prob: .5})\n",
    "    train_accuracy = accuracy.eval(feed_dict={x: X_train_s, y_: y_train_s, keep_prob: 1.})\n",
    "    print('training accuracy', train_accuracy)\n",
    "    \n",
    "#     validiation_accuracy = accuracy.eval(feed_dict={x: X_val_df, y_: y_val_df,keep_prob: 1.})\n",
    "#     print('validation accuracy', validiation_accuracy)\n",
    "    \n",
    "    test_accuracy = accuracy.eval(feed_dict={x: X_test, y_: y_test,keep_prob: 1.})\n",
    "    print('Test accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying out Different Filter sizes in a Third Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv12 = weight_variable([5, 5, 1, 32])\n",
    "#W_conv1 = weight_variable([2, 6, 1, 32])\n",
    "b_conv12 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv12 = tf.nn.relu(conv2d(x_audio, W_conv12) + b_conv12)\n",
    "h_pool12 = max_pool_2x2(h_conv12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv22 = weight_variable([5, 5, 32, 64])\n",
    "#W_conv2 = weight_variable([32, 8, 32, 64])\n",
    "b_conv22 = bias_variable([64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv22 = tf.nn.relu(conv2d(h_pool12, W_conv22) + b_conv22)\n",
    "h_pool22 = max_pool_2x2(h_conv22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc12 = weight_variable([32 * 3 * 64, 1024])\n",
    "#W_fc12 = weight_variable([32 * 3 * 64, 2048])\n",
    "b_fc12 = bias_variable([1024])\n",
    "#b_fc12 = bias_variable([2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_pool22_flat = tf.reshape(h_pool22, [-1, 32*3*64])\n",
    "h_fc12 = tf.nn.relu(tf.matmul(h_pool22_flat, W_fc12) + b_fc12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc12_drop = tf.nn.dropout(h_fc12, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc22 = weight_variable([1024, 3])\n",
    "#W_fc22 = weight_variable([2048, 3])\n",
    "b_fc22 = bias_variable([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_conv2 = tf.matmul(h_fc12_drop, W_fc22) + b_fc22\n",
    "\n",
    "cross_entropy2 = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv2), name ='Conv_Cross_Entropy2')\n",
    "train_step2 = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy2)\n",
    "correct_prediction2 = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1),name ='Conv_Accuracy2')\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2000/2000 [58:57<00:00,  1.74s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.985401\n",
      "Test accuracy 0.783505\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess3:\n",
    "    assert sess3 is tf.get_default_session()\n",
    "    sess3.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in tqdm(range(2000)):\n",
    "        sess3.run(train_step2,feed_dict={x: X_train_s, y_: y_train_s, keep_prob: 1.})\n",
    "    \n",
    "    train_accuracy2 = accuracy2.eval(feed_dict={x: X_train_s, y_: y_train_s, keep_prob: 1.})\n",
    "    print('training accuracy', train_accuracy2)\n",
    "    \n",
    "#     validiation_accuracy = accuracy.eval(feed_dict={x: X_val_df, y_: y_val_df,keep_prob: 1.})\n",
    "#     print('validation accuracy', validiation_accuracy)\n",
    "    \n",
    "    test_accuracy = accuracy2.eval(feed_dict={x: X_test, y_: y_test,keep_prob: 1.})\n",
    "    print('Test accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3000/3000 [1:57:30<00:00,  1.84s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy 0.989051\n",
      "Test accuracy 0.783505\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess4:\n",
    "    assert sess4 is tf.get_default_session()\n",
    "    sess4.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in tqdm(range(3000)):\n",
    "        sess4.run(train_step2,feed_dict={x: X_train_s, y_: y_train_s, keep_prob: .5})\n",
    "    \n",
    "    train_accuracy2 = accuracy2.eval(feed_dict={x: X_train_s, y_: y_train_s, keep_prob: 1.})\n",
    "    print('training accuracy', train_accuracy2)\n",
    "    \n",
    "#     validiation_accuracy = accuracy.eval(feed_dict={x: X_val_df, y_: y_val_df,keep_prob: 1.})\n",
    "#     print('validation accuracy', validiation_accuracy)\n",
    "    \n",
    "    test_accuracy = accuracy2.eval(feed_dict={x: X_test, y_: y_test,keep_prob: 1.})\n",
    "    print('Test accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT REFER  - CODE NOT IN USE: \n",
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.contrib import learn\n",
    "# from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def cnn_model_fn(features,labels,mode):\n",
    "#     # model function for CNN\n",
    "#     # Input Layer\n",
    "#     input_layer=tf.reshape(features,[-1,128,12,1]) # The first -1 means it is Dynamic Value to be passed based on \n",
    "#     # no# of records\n",
    "    \n",
    "#      # Convolutional Layer #1\n",
    "#     #1st Layer of Activation based filtering \n",
    "#     conv1 = tf.layers.conv2d(inputs=input_layer,filters=32,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu)\n",
    "#     # with same Padding the Output is still 128*12 space for each of 32 features extracted = 128*12*32\n",
    "    \n",
    "#     # Pooling Layer #1  - downsamples the Conv layers output by taking Max of the value with in the filter window\n",
    "#     pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "#     # With Pooling Layer#1  2x2 down sampling with stride =2 we have now 64*6 space for each of the 32 features\n",
    "#     # 64*6*32 \n",
    "    \n",
    "#     # Convolutional Layer #2 and Pooling Layer #2\n",
    "#     conv2 = tf.layers.conv2d(inputs=pool1,filters=64,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu)\n",
    "#     # Output is 64*6 space for each 64 features = 64*6*64\n",
    "#     pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "#     # Output is 32*3 space for each 64 features = 32*3*64\n",
    "    \n",
    "    \n",
    "#     # Dense Layer\n",
    "#     #pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "#     pool2_flat = tf.reshape(pool2, [-1, 32 * 3 * 64])\n",
    "#     dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "#     dropout = tf.layers.dropout(\n",
    "#     inputs=dense, rate=0.4, training=mode == learn.ModeKeys.TRAIN)\n",
    "    \n",
    "#     # Logits Layer\n",
    "#     logits = tf.layers.dense(inputs=dropout, units=3)\n",
    "\n",
    "#     loss = None\n",
    "#     train_op = None\n",
    "    \n",
    "#     # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "#     if mode != learn.ModeKeys.INFER:\n",
    "#         onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=3)\n",
    "#         loss = tf.losses.softmax_cross_entropy(\n",
    "#         onehot_labels=onehot_labels, logits=logits)\n",
    "        \n",
    "#     # Configure the Training Op (for TRAIN mode)\n",
    "#     if mode == learn.ModeKeys.TRAIN:\n",
    "#         train_op = tf.contrib.layers.optimize_loss(\n",
    "#             loss=loss,\n",
    "#             global_step=tf.contrib.framework.get_global_step(),\n",
    "#             learning_rate=0.001,\n",
    "#             optimizer=\"SGD\")\n",
    "    \n",
    "#     # Generate Predictions\n",
    "#     predictions = {\"classes\": tf.argmax(input=logits, axis=1),\"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")}\n",
    "\n",
    "#     # Return a ModelFnOps object\n",
    "#     return model_fn_lib.ModelFnOps(mode=mode, predictions=predictions, loss=loss, train_op=train_op)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
